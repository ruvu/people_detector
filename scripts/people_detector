#!/usr/bin/env python
import math
from collections import namedtuple
from itertools import groupby

import image_geometry
import message_filters
import numpy as np
import rospy
import tf
from cv_bridge import CvBridge
from geometry_msgs.msg import Point, Vector3, Pose, Quaternion
from image_recognition_msgs.srv import Recognize
from people_msgs.msg import Person, People
from sensor_msgs.msg import Image, CameraInfo
from std_msgs.msg import ColorRGBA
from visualization_msgs.msg import Marker, MarkerArray

Joint = namedtuple('Joint', ['group_id', 'name', 'p', 'point'])


class Skeleton(object):
    """
    Dictionary of all joints, the following joins could be available:

    Nose
    Neck
    Chest
    {L,R}{Shoulder,Elbow,Wrist,Hip,Knee,Ankle,Eye,Ear}
    """

    def __init__(self, bodyparts):
        """Constructor

        :param bodyparts: {name: Joint}
        """
        self.bodyparts = bodyparts
        self.links = [
            # head
            ('Nose', 'Neck'),
            ('LEar', 'LEye'),
            ('LEye', 'Nose'),
            ('REar', 'REye'),
            ('REye', 'Nose'),

            # body
            ('LShoulder', 'Neck'),
            ('LShoulder', 'LElbow'),
            ('LElbow', 'LWrist'),
            ('RElbow', 'RWrist'),
            ('RShoulder', 'Neck'),
            ('RShoulder', 'RElbow'),

            # legs
            ('LHip', 'Neck'),
            ('LAnkle', 'LKnee'),
            ('LKnee', 'LHip'),
            ('RHip', 'Neck'),
            ('RAnkle', 'RKnee'),
            ('RKnee', 'RHip'),
        ]

    # def __iter__(self):
    #     return self.bodyparts.__iter__()
    #
    # def __index__(self, value):
    #     return self.bodyparts.__index__(value)
    #
    def __getitem__(self, key):
        return self.bodyparts.__getitem__(key)

    def __contains__(self, item):
        return self.bodyparts.__contains__(item)

    #
    # def items(self):
    #     return self.bodyparts.items()

    def get_links(self):
        """
        :returns [Point], with point pairs for all the links
        """
        for (a, b) in self.links:
            if a in self.bodyparts and b in self.bodyparts:
                # rospy.loginfo("Add link {}".format((a, b)))
                yield self.bodyparts[a].point
                yield self.bodyparts[b].point
            else:
                # rospy.logwarn("Not all bodyparts of link {} found".format((a, b)))
                pass

    def __repr__(self):
        return '%s(%r)' % (self.__class__.__name__, self.bodyparts)


def color_map(N=256, normalized=False):
    def bitget(byteval, idx):
        return ((byteval & (1 << idx)) != 0)

    dtype = 'float32' if normalized else 'uint8'
    cmap = np.zeros((N, 3), dtype=dtype)
    for i in range(N):
        r = g = b = 0
        c = i + 1  # skip the first color (black)
        for j in range(8):
            r |= bitget(c, 0) << 7 - j
            g |= bitget(c, 1) << 7 - j
            b |= bitget(c, 2) << 7 - j
            c >>= 3

        cmap[i] = np.array([r, g, b])

    cmap = cmap / 255 if normalized else cmap
    return cmap


def get_param(name, default):
    if rospy.has_param(name):
        return rospy.get_param(name)
    else:
        rospy.logwarn('parameter %s not set, using the default value of %s', name, default)
        return rospy.get_param(name, default)


class PeopleDetector(object):
    padding = 5

    def __init__(self):
        rospy.loginfo('starting people_detector')
        self.bridge = CvBridge()

        # parameters
        self.threshold = float(get_param('~threshold', 0.2))
        self.heuristic = get_param('~heuristic', 'shoulder')

        # camera topics
        depth_info_sub = message_filters.Subscriber('camera/depth/camera_info', CameraInfo)
        depth_sub = message_filters.Subscriber('camera/depth/image', Image)
        rgb_sub = message_filters.Subscriber('camera/rgb/image', Image)

        # openpose
        self.recognize = rospy.ServiceProxy('pose_detector/recognize', Recognize)

        # published topics
        self.person_pub = rospy.Publisher('persons', People, queue_size=1)
        self.markers_pub = rospy.Publisher('~viz', MarkerArray, queue_size=1)
        self.regions_viz_pub = rospy.Publisher('~regions_viz', Image, queue_size=1)

        # before subscribing, wait for services
        rospy.loginfo('wait for service [%s]', self.recognize.resolved_name)
        self.recognize.wait_for_service()

        # private variables

        # self._ts = message_filters.TimeSynchronizer([depth_sub, depth_info_sub], 1)
        self._ts = message_filters.ApproximateTimeSynchronizer([rgb_sub, depth_sub, depth_info_sub], queue_size=3,
                                                               slop=0.1)
        self._ts.registerCallback(self.callback)
        rospy.loginfo('people_detector started')

    def callback(self, rgb, depth, depth_info):
        rospy.loginfo('got image cb')
        assert rgb.width == depth.width
        assert rgb.height == depth.height

        cam_model = image_geometry.PinholeCameraModel()
        cam_model.fromCameraInfo(depth_info)

        t = rospy.Time.now()
        try:
            data = self.recognize(image=rgb)
        except rospy.ServiceException as e:
            rospy.logwarn('openpose call failed: %s', e)
            return
        rospy.loginfo('openpose took %f seconds', (rospy.Time.now() - t).to_sec())

        joints = self.recognitions_to_joints(data.recognitions, depth, cam_model)

        # groupby group_id
        groups = []
        for group_id, js in groupby(joints, lambda j: j.group_id):
            groups.append(list(js))

        markers = MarkerArray()

        # visualize joints
        cmap = color_map(N=len(groups), normalized=True)
        for i, js in enumerate(groups):
            rospy.loginfo('found %s objects for group %s', len(js), i)

            points = [j.point for j in js]
            markers.markers.append(Marker(header=rgb.header,
                                          ns='joints',
                                          id=i,
                                          type=Marker.SPHERE_LIST,
                                          action=Marker.ADD,
                                          lifetime=rospy.Duration(1),
                                          points=points,
                                          scale=Vector3(0.1, 0.1, 0.1),
                                          color=ColorRGBA(cmap[i, 0], cmap[i, 1], cmap[i, 2], 1.0)))

        skeletons = [Skeleton({j.name: j for j in js}) for js in groups]

        # visualize links
        for i, s in enumerate(skeletons):
            markers.markers.append(Marker(header=rgb.header,
                                          ns='links',
                                          id=i,
                                          type=Marker.LINE_LIST,
                                          action=Marker.ADD,
                                          lifetime=rospy.Duration(1),
                                          points=list(s.get_links()),
                                          scale=Vector3(0.05, 0, 0),
                                          color=ColorRGBA(cmap[i, 0], cmap[i, 1], cmap[i, 2], 1.0)))

        # create persons
        persons = []
        for s in skeletons:
            if 'Neck' not in s:
                continue
            point3d = s['Neck'].point
            persons.append(Person(
                position=point3d,
                tags=self.get_person_tags(s)
            ))

        # visualize persons
        height = 1.8
        head = 0.2

        q = tf.transformations.quaternion_from_euler(-math.pi / 2, 0, 0)
        for i, p in enumerate(persons):
            text = ','.join(p.tags)
            y_max = p.position.y - 2 * head
            y_avg = p.position.y - head + height / 2
            p_avg = Point(p.position.x, y_avg, p.position.z)
            p_head = Point(p.position.x, y_max, p.position.z)
            markers.markers.append(Marker(header=rgb.header,
                                          ns='persons',
                                          id=i,
                                          type=Marker.CYLINDER,
                                          action=Marker.ADD,
                                          lifetime=rospy.Duration(1),
                                          pose=Pose(position=p_avg, orientation=Quaternion(*q)),
                                          scale=Vector3(0.2, 0.2, height),
                                          color=ColorRGBA(cmap[i, 0], cmap[i, 1], cmap[i, 2], 0.2)))

            markers.markers.append(Marker(header=rgb.header,
                                          ns='labels',
                                          id=i,
                                          type=Marker.TEXT_VIEW_FACING,
                                          action=Marker.ADD,
                                          lifetime=rospy.Duration(1),
                                          pose=Pose(position=p_head, orientation=Quaternion(*q)),
                                          text=text,
                                          scale=Vector3(0, 0, 0.2),
                                          color=ColorRGBA(cmap[i, 0], cmap[i, 1], cmap[i, 2], 1)))

        self.person_pub.publish(People(header=rgb.header, people=persons))
        # publish all markers in one go
        self.markers_pub.publish(markers)

    def recognitions_to_joints(self, recognitions, depth, cam_model):
        cv_depth = self.bridge.imgmsg_to_cv2(depth)
        regions_viz = np.zeros_like(cv_depth)

        joints = []
        for r in recognitions:
            assert len(r.categorical_distribution.probabilities) == 1
            pl = r.categorical_distribution.probabilities[0]
            label = pl.label
            p = pl.probability

            if p < self.threshold:
                continue

            roi = r.roi
            x_min = roi.x_offset - self.padding
            x_max = roi.x_offset + roi.width + self.padding
            y_min = roi.y_offset - self.padding
            y_max = roi.y_offset + roi.height + self.padding

            if x_min < 0 or y_min < 0 or x_max > depth.width or y_max > depth.height:
                continue  # outside of the image
            # rospy.loginfo('roi=[%d %d %d %d] in %dx%d', x_min, x_max, y_min, y_max, depth.width, depth.height)

            region = cv_depth[y_min:y_max, x_min:x_max]

            # debugging viz
            regions_viz[y_min:y_max, x_min:x_max] = cv_depth[y_min:y_max, x_min:x_max]
            self.regions_viz_pub.publish(self.bridge.cv2_to_imgmsg(regions_viz))

            # skip fully nan
            if np.all(np.isnan(region)):
                continue

            median = np.nanmedian(region)
            rospy.logdebug('region p=%f min=%f, max=%f, median=%f', p, np.nanmin(region), np.nanmax(region), median)

            # project to 3d
            u = roi.x_offset + roi.width // 2
            v = roi.y_offset + roi.height // 2
            d = median
            ray = np.array(cam_model.projectPixelTo3dRay((u, v)))
            point3d = ray * d

            rospy.logdebug('3d point of %s is %d,%d: %s', label, u, v, point3d)
            point = Point(*point3d)
            joints.append(Joint(r.group_id, label, p, point))
        return joints

    def get_person_tags(self, skeleton):
        tags = []
        for side in ('L', 'R'):
            try:
                if self.heuristic == 'shoulder':
                    other = skeleton[side + 'Shoulder'].point
                elif self.heuristic == 'head':
                    other = skeleton['Head'].point
                else:
                    raise ValueError('wrong heuristic')

                wrist = skeleton[side + 'Wrist'].point
                elbow = skeleton[side + 'Elbow'].point
            except KeyError as e:
                continue

            if wrist.y < other.y:
                tags.append(side + 'wave')

        rospy.loginfo(tags)
        return tags


if __name__ == '__main__':
    rospy.init_node('people_detector')
    PeopleDetector()
    rospy.spin()
