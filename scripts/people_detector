#!/usr/bin/env python
from collections import namedtuple
from cv_bridge import CvBridge
from itertools import groupby

import image_geometry
import message_filters
import numpy as np
import rospy
from geometry_msgs.msg import Point, Vector3
from image_recognition_msgs.srv import Recognize
from people_msgs.msg import PersonStamped
from sensor_msgs.msg import Image, CameraInfo
from std_msgs.msg import ColorRGBA
from visualization_msgs.msg import Marker, MarkerArray

Joint = namedtuple('Joint', ['group_id', 'name', 'p', 'point'])


class Skeleton(object):
    """
    Dictionary of all joints, the following joins could be available:

    Nose
    Neck
    Chest
    {L,R}{Shoulder,Elbow,Wrist,Hip,Knee,Ankle,Eye,Ear}
    """

    def __init__(self, bodyparts):
        """Constructor

        :param bodyparts: {name: Joint}
        """
        self.bodyparts = bodyparts
        self.links = [
            # head
            ('Nose', 'Neck'),
            ('LEar', 'LEye'),
            ('LEye', 'Nose'),
            ('REar', 'REye'),
            ('REye', 'Nose'),

            # body
            ('LShoulder', 'Neck'),
            ('LShoulder', 'LElbow'),
            ('LElbow', 'LWrist'),
            ('RElbow', 'RWrist'),
            ('RShoulder', 'Neck'),
            ('RShoulder', 'RElbow'),

            # legs
            ('LHip', 'Neck'),
            ('LAnkle', 'LKnee'),
            ('LKnee', 'LHip'),
            ('RHip', 'Neck'),
            ('RAnkle', 'RKnee'),
            ('RKnee', 'RHip'),
        ]

    # def __iter__(self):
    #     return self.bodyparts.__iter__()
    #
    # def __index__(self, value):
    #     return self.bodyparts.__index__(value)
    #
    # def __getitem__(self, key):
    #     return self.bodyparts.__getitem__(key)
    #
    # def items(self):
    #     return self.bodyparts.items()

    def get_links(self):
        """
        :returns [Point], with point pairs for all the links
        """
        for (a, b) in self.links:
            if a in self.bodyparts and b in self.bodyparts:
                yield self.bodyparts[a].point
                yield self.bodyparts[b].point
                rospy.loginfo("Add link {}".format((a, b)))
            else:
                rospy.logwarn("Not all bodyparts of link {} found".format((a, b)))

    def __repr__(self):
        return '%s(%r)' % (self.__class__.__name__, self.bodyparts)


def color_map(N=256, normalized=False):
    def bitget(byteval, idx):
        return ((byteval & (1 << idx)) != 0)

    dtype = 'float32' if normalized else 'uint8'
    cmap = np.zeros((N, 3), dtype=dtype)
    for i in range(N):
        r = g = b = 0
        c = i
        for j in range(8):
            r |= bitget(c, 0) << 7 - j
            g |= bitget(c, 1) << 7 - j
            b |= bitget(c, 2) << 7 - j
            c >>= 3

        cmap[i] = np.array([r, g, b])

    cmap = cmap / 255 if normalized else cmap
    return cmap


def get_param(name, default):
    if rospy.has_param(name):
        return rospy.get_param(name)
    else:
        rospy.logwarn('parameter %s not set, using the default value of %s', name, default)
        return rospy.get_param(name, default)


class PeopleDetector(object):
    padding = 5

    def __init__(self):
        rospy.loginfo('starting people_detector')
        self.bridge = CvBridge()

        # parameters
        self.threshold = get_param('threshold', 0.2)

        # camera topics
        depth_info_sub = message_filters.Subscriber('/camera/depth/camera_info', CameraInfo)
        depth_sub = message_filters.Subscriber('/camera/depth/image', Image)
        rgb_sub = message_filters.Subscriber('/camera/rgb/image_color', Image)

        # openpose
        self.recognize = rospy.ServiceProxy('recognize', Recognize)

        # published topics
        self.person_pub = rospy.Publisher('persons', PersonStamped, queue_size=1)
        self.markers_pub = rospy.Publisher('viz', MarkerArray, queue_size=1)

        # private variables

        # self._ts = message_filters.TimeSynchronizer([depth_sub, depth_info_sub], 1)
        self._ts = message_filters.ApproximateTimeSynchronizer([rgb_sub, depth_sub, depth_info_sub], queue_size=3,
                                                               slop=0.1)
        self._ts.registerCallback(self.callback)

        rospy.wait_for_service(self.recognize)
        rospy.loginfo('people_detector started')

    def callback(self, rgb, depth, depth_info):
        rospy.loginfo('got image cb')
        assert rgb.width == depth.width
        assert rgb.height == depth.height

        t = rospy.Time.now()
        data = self.recognize(image=rgb)
        rospy.loginfo('openpose took %f seconds', (rospy.Time.now() - t).to_sec())

        joints = self.recognitions_to_joints(data.recognitions, depth, depth_info)

        # groupby group_id
        groups = {}
        for group_id, js in groupby(joints, lambda j: j.group_id):
            groups[group_id] = list(js)

        # pushlish all joints
        cmap = color_map(N=len(groups), normalized=True)
        markers = MarkerArray()
        for i, (_, js) in enumerate(groups.items()):
            rospy.loginfo('found %s objects for group %s', len(js), i)

            points = [j.point for j in js]
            markers.markers.append(Marker(header=rgb.header,
                                          ns='joints',
                                          id=i,
                                          type=Marker.SPHERE_LIST,
                                          action=Marker.ADD,
                                          lifetime=rospy.Duration(1),
                                          points=points,
                                          scale=Vector3(0.1, 0.1, 0.1),
                                          color=ColorRGBA(cmap[i, 0], cmap[i, 1], cmap[i, 2], 1.0)))

            s = Skeleton({j.name: j for j in js})
            markers.markers.append(Marker(header=rgb.header,
                                          ns='links',
                                          id=i,
                                          type=Marker.LINE_LIST,
                                          action=Marker.ADD,
                                          lifetime=rospy.Duration(1),
                                          points=list(s.get_links()),
                                          scale=Vector3(0.05, 0, 0),
                                          color=ColorRGBA(cmap[i, 0], cmap[i, 1], cmap[i, 2], 1.0)))
        self.markers_pub.publish(markers)


        # create person
        # person = PersonStamped(header=rgb.header, person=Person(
        #     position=Point(point3d[0], point3d[1], point3d[2]),
        # ))
        #
        # self.person_pub.publish(person)

    def recognitions_to_joints(self, recognitions, depth, depth_info):
        cv_depth = self.bridge.imgmsg_to_cv2(depth)

        joints = []
        for r in recognitions:
            assert len(r.categorical_distribution.probabilities) == 1
            pl = r.categorical_distribution.probabilities[0]
            label = pl.label
            p = pl.probability

            if p < self.threshold:
                continue

            roi = r.roi
            x_min = roi.x_offset - self.padding
            x_max = roi.x_offset + roi.width + self.padding
            y_min = roi.y_offset - self.padding
            y_max = roi.y_offset + roi.height + self.padding

            if x_min < 0 or y_min < 0 or x_max > depth.width or y_max > depth.height:
                continue  # outside of the image
            # rospy.loginfo('roi=[%d %d %d %d] in %dx%d', x_min, x_max, y_min, y_max, depth.width, depth.height)

            region = cv_depth[x_min:x_max, y_min:y_max]

            # skip fully nan
            if np.all(np.isnan(region)):
                continue

            median = np.nanmedian(region)
            rospy.loginfo('region p=%f min=%f, max=%f, median=%f', p, np.nanmin(region), np.nanmax(region), median)

            # project to 3d
            u = roi.x_offset + roi.width // 2
            v = roi.y_offset + roi.height // 2
            d = median
            cam_model = image_geometry.PinholeCameraModel()
            cam_model.fromCameraInfo(depth_info)
            ray = np.array(cam_model.projectPixelTo3dRay((u, v)))
            point3d = ray * d

            rospy.loginfo('3d point of pixel %d,%d: %s', u, v, point3d)
            point = Point(point3d[0], point3d[1], point3d[2])
            joints.append(Joint(r.group_id, label, p, point))
        return joints


if __name__ == '__main__':
    rospy.init_node('people_detector')
    PeopleDetector()
    rospy.spin()
